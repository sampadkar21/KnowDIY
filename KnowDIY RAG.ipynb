{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13275625,"sourceType":"datasetVersion","datasetId":8413063}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install PyMuPDF -qqq\n!pip install llama-cpp-python -qqq\n!pip install langchain langchain_huggingface -qqq\n!pip install -U qdrant-client -qqq\n!pip install gradio -qqq","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport re\nimport fitz\nimport shutil\nfrom typing import List, Tuple, Dict\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import defaultdict\nfrom sentence_transformers import SentenceTransformer, CrossEncoder\nfrom qdrant_client import QdrantClient\nfrom qdrant_client.http.models import (\n    VectorParams,\n    Distance,\n    PointStruct\n)\nimport uuid\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nimport torch\nfrom llama_cpp import Llama\nfrom huggingface_hub import login\nimport gradio as gr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:22:40.997775Z","iopub.execute_input":"2025-10-19T10:22:40.998426Z","iopub.status.idle":"2025-10-19T10:22:41.003060Z","shell.execute_reply.started":"2025-10-19T10:22:40.998402Z","shell.execute_reply":"2025-10-19T10:22:41.002419Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"gemma_3\")\nlogin(token=secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:02:42.685454Z","iopub.execute_input":"2025-10-19T10:02:42.686147Z","iopub.status.idle":"2025-10-19T10:02:43.005519Z","shell.execute_reply.started":"2025-10-19T10:02:42.686121Z","shell.execute_reply":"2025-10-19T10:02:43.004880Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class EmbeddingManager:\n    def __init__(self, model_name=\"ibm-granite/granite-embedding-english-r2\", device='cuda:0'):\n        self.model_name = model_name\n        self.device = device\n        self.model = None\n        self._initialize_model()\n\n    def _initialize_model(self):\n        try:\n            self.model = SentenceTransformer(\n                self.model_name,\n                trust_remote_code=True,\n                device=self.device\n            )\n            self.tokenizer = self.model.tokenizer\n            print(f\"Embedding Model '{self.model_name}' Initialized on {self.device}\")\n        except Exception as e:\n            print(\"Model Not Found:\", e)\n\n    def get_embedding(self, txt:List[str]):\n        if not self.model:\n            raise ValueError(\"Model not loaded\")\n            \n        print(f\"Generating embeddings for {len(txt)} texts ... \")\n        embeddings = self.model.encode(txt, show_progress_bar=True)\n        print(f\"Generated embeddings with shape: {embeddings.shape}\")\n        return embeddings\n\n    def get_embedding_dim(self):\n        dim = self.model.get_sentence_embedding_dimension()\n        print(\"Model Dimension:\", dim)\n\nembedding_model = EmbeddingManager()\nembedding_model.get_embedding_dim()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:03:35.270357Z","iopub.execute_input":"2025-10-19T10:03:35.271100Z","iopub.status.idle":"2025-10-19T10:03:37.234965Z","shell.execute_reply.started":"2025-10-19T10:03:35.271068Z","shell.execute_reply":"2025-10-19T10:03:37.234244Z"}},"outputs":[{"name":"stdout","text":"Embedding Model 'ibm-granite/granite-embedding-english-r2' Initialized on cuda:0\nModel Dimension: 768\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"topic_regex = re.compile(r'(\\d{3})\\s+[A-Z]+')\ntopic_dict = []\n\ndoc = fitz.open(\"/kaggle/input/diy-book/DIY_BOOK.pdf\")\nfull_text = \"\"\n\nfor page in doc:\n    full_text += page.get_text()\n\nsplits = list(topic_regex.finditer(full_text))\nif splits:\n    preamble = full_text[:splits[0].start()].strip()\n    for i, match in enumerate(splits):\n        topic_num = match.group(1)\n        topic_start = match.start()\n        topic_end = splits[i+1].start() if i+1 < len(splits) else len(full_text)\n        topic_content = full_text[topic_start:topic_end].strip()\n        topic_match = re.search(r'^(\\d{3}\\s+[A-Z ]+)\\s*(.*)', topic_content, re.DOTALL)\n        if topic_match:\n            topic_name = topic_match.group(1)\n            content = topic_match.group(2)\n            topic_name_without_num = re.sub(r'^\\d{3}\\s*', '', topic_name).strip()\n        else:\n            topic_name_without_num = \"\"\n            content = topic_content\n        if len(content)>50:\n            topic_dict.append(\n                {\n                    'topic_no': int(topic_num),\n                    'topic_name': topic_name_without_num,\n                    'content': content\n                }\n            )\nelse:\n    topic_dict.append({'topic_no': None, 'topic_name': 'FULL_TEXT', 'content': full_text.strip()})\n\ntopic_dict = topic_dict[1:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:03:41.406893Z","iopub.execute_input":"2025-10-19T10:03:41.407177Z","iopub.status.idle":"2025-10-19T10:03:42.450929Z","shell.execute_reply.started":"2025-10-19T10:03:41.407157Z","shell.execute_reply":"2025-10-19T10:03:42.449918Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class PreprocessPdf:\n    def __init__(self, model, content_list: List[Dict]):\n        self.model = model\n        self.content_list = content_list\n        self.text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n            tokenizer=self.model,\n            chunk_size=512,\n            chunk_overlap=50,\n            separators=[\".\"]\n        )\n\n    def clean_text(self,txt:str):\n        txt = txt.replace('\\n',' ')\n        return txt\n\n    def process_content(self) -> List[Dict]:\n        all_chunks_metadata = []\n        \n        for topic_item in self.content_list:\n            topic_no = topic_item.get('topic_no')\n            topic_name = topic_item.get('topic_name') \n            full_text = topic_item.get('content', '') \n    \n            if not full_text:\n                continue\n\n            chunks = self.text_splitter.split_text(full_text)\n\n            for idx, chunk in enumerate(chunks):\n                chunk = self.clean_text(chunk)\n                chunk_token_count = len(self.model(chunk)['input_ids'])\n                all_chunks_metadata.append({\n                    'topic_no': topic_no,\n                    'chunk_no': idx,\n                    'topic': topic_name,\n                    'chunk_char_count': len(chunk),\n                    'chunk_word_count': len(chunk.split()),\n                    'chunk_token_count': chunk_token_count,\n                    'text': chunk.lower()\n                })\n        \n        return all_chunks_metadata\n\n\npp = PreprocessPdf(embedding_model.tokenizer,topic_dict)\nmetadata = pp.process_content()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:03:48.564429Z","iopub.execute_input":"2025-10-19T10:03:48.565105Z","iopub.status.idle":"2025-10-19T10:03:49.816032Z","shell.execute_reply.started":"2025-10-19T10:03:48.565075Z","shell.execute_reply":"2025-10-19T10:03:49.815410Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"len(metadata)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:03:54.488598Z","iopub.execute_input":"2025-10-19T10:03:54.488860Z","iopub.status.idle":"2025-10-19T10:03:54.493788Z","shell.execute_reply.started":"2025-10-19T10:03:54.488842Z","shell.execute_reply":"2025-10-19T10:03:54.493109Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"378"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"metadata[:2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:04:14.071767Z","iopub.execute_input":"2025-10-19T10:04:14.072032Z","iopub.status.idle":"2025-10-19T10:04:14.077498Z","shell.execute_reply.started":"2025-10-19T10:04:14.072013Z","shell.execute_reply":"2025-10-19T10:04:14.076822Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[{'topic_no': 1,\n  'chunk_no': 0,\n  'topic': 'BUILD A BASIC TOOLBOX',\n  'chunk_char_count': 2130,\n  'chunk_word_count': 346,\n  'chunk_token_count': 475,\n  'text': 'from simple fix-ups to major home improvements, the right tools make all the difference. novice diyers should assemble a toolbox with a handful of essential tools that are most widely applicable to any job. additional materials can be purchased as required, expanding your arsenal as your experience and skill set improve. choose a toolbox with ample storage space for large, irregular items such as a hammer and square, but one thatâ€™s light and compact enough for easy portability.  hammer from hanging a picture frame to building a wall, the right hammer is an essential household tool. youâ€™ll find specialized models for heavy-duty framing and for fine woodwork, but a good basic model should be medium weight (16 to 20 ounces) with a smooth-faced head, rip claw, and non-wood handle.  screwdrivers whether youâ€™re putting something together or taking it apart, the right screwdriver makes all the difference. youâ€™ll find various types of screws in everything from woodworking to automotive work, and each type requires a matching screwdriver, so youâ€™ll need a variety. common screw types include flat-head, phillips, square-drive, torxâ„¢, and pozidriv.  tape measure the tape measure will likely get the most mileage of all your tools. a 25- to 30-foot tape will suffice for most jobs, big and small.  utility knife you can use a razor-sharp utility knife to open up packages, cut roof shingles, trim insulation, and so much more. choose a model that offers convenient in-handle storage for extra blades.  torpedo level this handy tool utilizes a bubble vial to check for level and plumb on anything from picture frames and shelves to fence posts. although longer levels are more accurate, a torpedo level comes close and fits in a toolbox.  speed square this is a very handy tool used for simple measuring, drawing straight lines, and marking angles. it also makes a grade-cutting guide for a circular saw.  chalk line another member of the marking and measuring family of tools, a chalk line can be very useful when working with drywall, roofing, floor installation, or any other unusually large piece of construction material'},\n {'topic_no': 1,\n  'chunk_no': 1,\n  'topic': 'BUILD A BASIC TOOLBOX',\n  'chunk_char_count': 1952,\n  'chunk_word_count': 314,\n  'chunk_token_count': 448,\n  'text': '.  chalk line another member of the marking and measuring family of tools, a chalk line can be very useful when working with drywall, roofing, floor installation, or any other unusually large piece of construction material.  safety goggles arguably the most important item to keep in a toolbox is a pair of safety goggles. these will obviously help keep dangerous particles out of your eyes while cutting or performing demo work, but they can also be worn while painting to protect from flying specks.  wood chisel a Â½-inch wood chisel is useful for many different applications, not just carving and shaping wood, as itâ€™s actually intended to do. much to the manufacturerâ€™s chagrin, chisels can be used as everything from a miniature pry bar to a paint scraper. keep two chisels handy: one for cutting wood and another for general usage.  wrenches available with adjustable jaws or with fixed box-end designs, wrenches provide a firm grip for loosening and tightening bolts, nuts, and other faceted fasteners.  pliers available in many sizes and designs, pliers tightly grasp and hold items that canâ€™t be held by your fingers alone.  tongue-and-groove pliers the adjustable mouth of tongue- and-groove pliers makes this tool handy for grabbing large items as well as small. its primary use is for grabbing plumbing fixtures too big for standard wrenches, and the long handles provide plenty of leverage.  locking pliers known by the brand name vise-grip, this tool works like adjustable pliers but locks into place with incredible grip, freeing your hands for other work.  allen wrenches appliances, machinery, and power equipment often have screws with a hexagonal recess set in their heads. these screws require allen wrenches, which are small l-shaped tools in sets of both metric and imperial measurements.  socket wrench set these modular systems include a wrench handle and individual sockets of different sizes, as well as extenders and adapters'}]"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"df = pd.DataFrame(metadata)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:04:19.802056Z","iopub.execute_input":"2025-10-19T10:04:19.802343Z","iopub.status.idle":"2025-10-19T10:04:19.810750Z","shell.execute_reply.started":"2025-10-19T10:04:19.802323Z","shell.execute_reply":"2025-10-19T10:04:19.810044Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df.sample(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:04:21.678601Z","iopub.execute_input":"2025-10-19T10:04:21.679116Z","iopub.status.idle":"2025-10-19T10:04:21.706482Z","shell.execute_reply.started":"2025-10-19T10:04:21.679092Z","shell.execute_reply":"2025-10-19T10:04:21.705854Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"     topic_no  chunk_no            topic  chunk_char_count  chunk_word_count  \\\n125       113         0  UPDATE FIXTURES              2201               383   \n222       197         0    GET A COMPLEX              2079               337   \n196       174         0   REPAIR PLASTER               713               127   \n19         16         0     GET SOME AIR               989               160   \n176       157         0  PERFORM SURGERY              1053               174   \n\n     chunk_token_count                                               text  \n125                465  your primary concern when you are selecting a ...  \n222                415  crown molding and casing are both available in...  \n196                157  for plaster repairs, you can use a powder-base...  \n19                 210  air power is great way to take your home shop ...  \n176                224  in some cases, the best solution may be to cut...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_no</th>\n      <th>chunk_no</th>\n      <th>topic</th>\n      <th>chunk_char_count</th>\n      <th>chunk_word_count</th>\n      <th>chunk_token_count</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>125</th>\n      <td>113</td>\n      <td>0</td>\n      <td>UPDATE FIXTURES</td>\n      <td>2201</td>\n      <td>383</td>\n      <td>465</td>\n      <td>your primary concern when you are selecting a ...</td>\n    </tr>\n    <tr>\n      <th>222</th>\n      <td>197</td>\n      <td>0</td>\n      <td>GET A COMPLEX</td>\n      <td>2079</td>\n      <td>337</td>\n      <td>415</td>\n      <td>crown molding and casing are both available in...</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>174</td>\n      <td>0</td>\n      <td>REPAIR PLASTER</td>\n      <td>713</td>\n      <td>127</td>\n      <td>157</td>\n      <td>for plaster repairs, you can use a powder-base...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>16</td>\n      <td>0</td>\n      <td>GET SOME AIR</td>\n      <td>989</td>\n      <td>160</td>\n      <td>210</td>\n      <td>air power is great way to take your home shop ...</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>157</td>\n      <td>0</td>\n      <td>PERFORM SURGERY</td>\n      <td>1053</td>\n      <td>174</td>\n      <td>224</td>\n      <td>in some cases, the best solution may be to cut...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:04:24.916201Z","iopub.execute_input":"2025-10-19T10:04:24.916662Z","iopub.status.idle":"2025-10-19T10:04:24.939733Z","shell.execute_reply.started":"2025-10-19T10:04:24.916642Z","shell.execute_reply":"2025-10-19T10:04:24.939035Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"         topic_no    chunk_no  chunk_char_count  chunk_word_count  \\\ncount  378.000000  378.000000        378.000000        378.000000   \nmean   166.378307    0.164021       1144.402116        195.296296   \nstd     94.615134    0.573117        684.830705        108.101887   \nmin      1.000000    0.000000         76.000000         15.000000   \n25%     87.000000    0.000000        635.750000        109.750000   \n50%    168.000000    0.000000       1016.500000        174.000000   \n75%    246.750000    0.000000       1572.500000        275.750000   \nmax    321.000000    6.000000       7605.000000        987.000000   \n\n       chunk_token_count  \ncount         378.000000  \nmean          253.902116  \nstd           144.256250  \nmin            28.000000  \n25%           141.000000  \n50%           226.500000  \n75%           356.500000  \nmax          1468.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic_no</th>\n      <th>chunk_no</th>\n      <th>chunk_char_count</th>\n      <th>chunk_word_count</th>\n      <th>chunk_token_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>378.000000</td>\n      <td>378.000000</td>\n      <td>378.000000</td>\n      <td>378.000000</td>\n      <td>378.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>166.378307</td>\n      <td>0.164021</td>\n      <td>1144.402116</td>\n      <td>195.296296</td>\n      <td>253.902116</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>94.615134</td>\n      <td>0.573117</td>\n      <td>684.830705</td>\n      <td>108.101887</td>\n      <td>144.256250</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>76.000000</td>\n      <td>15.000000</td>\n      <td>28.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>87.000000</td>\n      <td>0.000000</td>\n      <td>635.750000</td>\n      <td>109.750000</td>\n      <td>141.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>168.000000</td>\n      <td>0.000000</td>\n      <td>1016.500000</td>\n      <td>174.000000</td>\n      <td>226.500000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>246.750000</td>\n      <td>0.000000</td>\n      <td>1572.500000</td>\n      <td>275.750000</td>\n      <td>356.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>321.000000</td>\n      <td>6.000000</td>\n      <td>7605.000000</td>\n      <td>987.000000</td>\n      <td>1468.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"class VectorStore:\n    def __init__(self, db_name: str, db_path: str, embedding_model):\n        self.db_name = db_name\n        self.embedding_model = embedding_model\n        self.db_path = db_path  \n        self.client = None\n        self._initialize_vector_store()\n\n    def _initialize_vector_store(self):\n        try:\n            self.client = QdrantClient(path=self.db_path)\n            \n            print(f\"Vector Store initialized successfully at path: '{self.db_path}'\")\n        except Exception as e:\n            print(f\"Vector Store initialization failed: {e}\")\n\n    def create_store(self, dim=768):\n        if not self.client:\n            print(\"Client not initialized. Cannot create store.\")\n            return\n        try:\n            if self.client.collection_exists(self.db_name):\n                self.client.delete_collection(self.db_name)\n                print(f\"Dropped existing collection: '{self.db_name}'\")\n\n            self.client.create_collection(\n                collection_name=self.db_name,\n                vectors_config=VectorParams(size=dim, distance=Distance.COSINE)\n            )\n            \n            print(f\"Vector Store Collection '{self.db_name}' Created Successfully with dimension {dim}\")\n\n        except Exception as e:\n            print(f\"Vector Store Creation Failed: {e}\")\n\n    def add_documents(self, data_list: List[Dict]):\n        if not self.client:\n            print(\"No Client found. Cannot add documents.\")\n            return\n        try:\n            texts = [d['text'] for d in data_list]\n            embeddings = self.embedding_model.get_embedding(texts)\n            if embeddings is None:\n                print(\"Embedding generation failed. Aborting document addition.\")\n                return\n\n            points = []\n            for idx, d in enumerate(data_list):\n                points.append(\n                    PointStruct(\n                        id=str(uuid.uuid4()),  \n                        vector=embeddings[idx].tolist(),  \n                        payload={\n                            \"topic_no\": d.get(\"topic_no\"),\n                            \"chunk_no\": d.get(\"chunk_no\"),\n                            \"topic\": d.get(\"topic\"),\n                            \"chunk_char_count\": d.get(\"chunk_char_count\"),\n                            \"chunk_word_count\": d.get(\"chunk_word_count\"),\n                            \"chunk_token_count\": d.get(\"chunk_token_count\"),\n                            \"text\": d.get(\"text\")\n                        }\n                    )\n                )\n            \n            if not points:\n                print(\"No documents to add.\")\n                return\n\n            self.client.upsert(collection_name=self.db_name, points=points, wait=True)\n            print(f\"{len(points)} documents added to Qdrant Vector Store\")\n        except Exception as e:\n            print(f\"Error adding documents: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:04:27.399380Z","iopub.execute_input":"2025-10-19T10:04:27.399905Z","iopub.status.idle":"2025-10-19T10:04:27.408666Z","shell.execute_reply.started":"2025-10-19T10:04:27.399886Z","shell.execute_reply":"2025-10-19T10:04:27.407887Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"DB_STORAGE_PATH = \"/kaggle/working/vectordb\" \nCOLLECTION_NAME = \"KnowDIY_DB\"\n\nif os.path.exists(DB_STORAGE_PATH):\n    print(f\"Found existing database path. Deleting '{DB_STORAGE_PATH}'...\")\n    try:\n        shutil.rmtree(DB_STORAGE_PATH)\n        print(\"Successfully cleaned old database directory.\")\n    except Exception as e:\n        print(f\"Error cleaning directory: {e}\")\nelse:\n    print(f\"Directory '{DB_STORAGE_PATH}' not found. No cleaning needed.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:04:31.244508Z","iopub.execute_input":"2025-10-19T10:04:31.244986Z","iopub.status.idle":"2025-10-19T10:04:31.249790Z","shell.execute_reply.started":"2025-10-19T10:04:31.244966Z","shell.execute_reply":"2025-10-19T10:04:31.249126Z"}},"outputs":[{"name":"stdout","text":"Directory '/kaggle/working/vectordb' not found. No cleaning needed.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"vs = VectorStore(COLLECTION_NAME, DB_STORAGE_PATH, embedding_model)\nvs.create_store(dim=768)\nvs.add_documents(metadata)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:04:34.046339Z","iopub.execute_input":"2025-10-19T10:04:34.046575Z","iopub.status.idle":"2025-10-19T10:04:57.870764Z","shell.execute_reply.started":"2025-10-19T10:04:34.046560Z","shell.execute_reply":"2025-10-19T10:04:57.870123Z"}},"outputs":[{"name":"stdout","text":"Vector Store initialized successfully at path: '/kaggle/working/vectordb'\nVector Store Collection 'KnowDIY_DB' Created Successfully with dimension 768\nGenerating embeddings for 378 texts ... \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/12 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd259761113243eda88d1fde9079b8a4"}},"metadata":{}},{"name":"stderr","text":"W1019 10:04:40.765000 37 torch/_inductor/utils.py:1137] [1/0] Not enough SMs to use max_autotune_gemm mode\n","output_type":"stream"},{"name":"stdout","text":"Generated embeddings with shape: (378, 768)\n378 documents added to Qdrant Vector Store\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"class Retriever:\n    def __init__(self, emb_model: EmbeddingManager, vectordb: VectorStore):\n        self.emb_model = emb_model\n        self.vectordb = vectordb\n\n    def retrieve(self, query: str, top_k: int = 5, threshold: float = 0.3):\n        query_emb = self.emb_model.get_embedding([query])\n\n        out = self.vectordb.client.query_points(\n            collection_name=self.vectordb.db_name,\n            query=query_emb[0],  \n            limit=top_k,\n            with_payload=True\n        )\n        \n        texts = [o.payload['text'] for o in out.points if o.score > threshold]\n        return texts\n\nretriever = Retriever(emb_model=embedding_model, vectordb=vs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:05:04.641336Z","iopub.execute_input":"2025-10-19T10:05:04.641880Z","iopub.status.idle":"2025-10-19T10:05:04.647224Z","shell.execute_reply.started":"2025-10-19T10:05:04.641858Z","shell.execute_reply":"2025-10-19T10:05:04.646607Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class ReRanker:\n    def __init__(self, model_name=\"ibm-granite/granite-embedding-reranker-english-r2\", device='cuda:0'):\n        self.model_name = model_name\n        self.device = device\n        self._initialize_model()\n\n    def _initialize_model(self):\n        try:\n            self.model = CrossEncoder(\n                self.model_name,\n                trust_remote_code=True,\n                device=self.device\n            )\n            print(f\"ReRanker Model '{self.model_name}' initialized on {self.device}\")\n        except Exception as e:\n            print(\"Model Not Found:\", e)\n\n    def rerank(self, query: str, passages: List[str]):\n        pairs = [(query, passage) for passage in passages]\n        scores = self.model.predict(pairs)\n        ranked_indices = np.argsort(scores)[::-1]\n        ranked_passages = [passages[i] for i in ranked_indices]\n        return ranked_passages, scores[ranked_indices]\n\n    def get_embedding_dim(self):\n        dim = self.model.config.hidden_size\n        print(\"Model Dimension:\", dim)\n\nreranker = ReRanker()\nreranker.get_embedding_dim()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:05:17.059065Z","iopub.execute_input":"2025-10-19T10:05:17.059800Z","iopub.status.idle":"2025-10-19T10:05:18.106814Z","shell.execute_reply.started":"2025-10-19T10:05:17.059778Z","shell.execute_reply":"2025-10-19T10:05:18.106025Z"}},"outputs":[{"name":"stdout","text":"ReRanker Model 'ibm-granite/granite-embedding-reranker-english-r2' initialized on cuda:0\nModel Dimension: 768\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"PROMPT_TEMPLATE = \"\"\"You are an expert DIY assistant. Your tone is helpful, confident, and you give clear, direct answers.\n\nYour task is to answer the user's question clearly, confidently, and directly. Provide step-by-step instructions if applicable. Do not provide explanations about where the information came from. Do not ask the user any questions. \n\n**Your Task:**\n1.  Analyze the User Question.\n2.  Locate the relevant information *only* from the Knowledge Base.\n3.  Answer the question directly and helpfully. If the Knowledge Base provides steps, list them clearly.\n\n**Critical Rules:**\n* **DO NOT** mention the Knowledge Base. Answer as if this is your own expert knowledge.\n* **DO NOT** use any phrases like \"According to the context,\" \"The provided text states,\" or \"Based on the information...\".\n* If the Knowledge Base does **not** contain the answer to the question, you must state that you cannot provide that specific information. Do not invent an answer.\n\n**Knowledge Base:**\n---\n{context}\n---\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:05:33.000050Z","iopub.execute_input":"2025-10-19T10:05:33.000374Z","iopub.status.idle":"2025-10-19T10:05:33.004630Z","shell.execute_reply.started":"2025-10-19T10:05:33.000353Z","shell.execute_reply":"2025-10-19T10:05:33.003872Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"llm = Llama.from_pretrained(\n\trepo_id=\"google/gemma-3-4b-it-qat-q4_0-gguf\",\n\tfilename=\"gemma-3-4b-it-q4_0.gguf\",\n \tn_ctx=4096,       \n \tn_gpu_layers=-1,   \n \tverbose=False     \n)\n\nprint(f\"Model loaded successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:05:36.751655Z","iopub.execute_input":"2025-10-19T10:05:36.752134Z","iopub.status.idle":"2025-10-19T10:05:51.112956Z","shell.execute_reply.started":"2025-10-19T10:05:36.752114Z","shell.execute_reply":"2025-10-19T10:05:51.112319Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"./gemma-3-4b-it-q4_0.gguf:   0%|          | 0.00/3.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1698418797ac44dc81b453b27b8f7b18"}},"metadata":{}},{"name":"stderr","text":"llama_context: n_ctx_per_seq (4096) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\nllama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n","output_type":"stream"},{"name":"stdout","text":"Model loaded successfully.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"def chatbot(user_query: str, max_tokens:int=512):  \n    retrieved_chunks = retriever.retrieve(user_query, top_k=5)\n    reranked_chunks, scores = reranker.rerank(user_query, retrieved_chunks)\n    context = \"\\n\\n\".join(reranked_chunks)\n    \n    system_prompt = PROMPT_TEMPLATE.format(context=context)\n    \n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": user_query}\n    ]\n    \n    try:\n        output_generator = llm.create_chat_completion(\n            messages=messages,\n            max_tokens=384,\n            temperature=0.9,\n            top_p=0.95,\n            stream=True  \n        )\n        \n        for chunk in output_generator:\n            delta = chunk[\"choices\"][0][\"delta\"]\n            content = delta.get(\"content\")\n            \n            if content:\n                yield content  \n\n    except Exception as e:\n        print(\"Model generation error:\", str(e))\n        yield \"Sorry, something went wrong during response generation.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:23:52.112766Z","iopub.execute_input":"2025-10-19T10:23:52.113400Z","iopub.status.idle":"2025-10-19T10:23:52.119055Z","shell.execute_reply.started":"2025-10-19T10:23:52.113378Z","shell.execute_reply":"2025-10-19T10:23:52.118120Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"query = \"what are the different types of screw available\"\n\nprint(f\"User: {query}\")\nprint(\"Chatbot: \", end=\"\", flush=True)\n\nfor text_chunk in chatbot(query):\n    print(text_chunk, end=\"\", flush=True)\n\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:06:02.285216Z","iopub.execute_input":"2025-10-19T10:06:02.285508Z","iopub.status.idle":"2025-10-19T10:07:39.913584Z","shell.execute_reply.started":"2025-10-19T10:06:02.285490Z","shell.execute_reply":"2025-10-19T10:07:39.912742Z"}},"outputs":[{"name":"stdout","text":"User: what are the different types of screw available\nChatbot: Generating embeddings for 1 texts ... \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ac328d79ed94018a21333f226a62ab0"}},"metadata":{}},{"name":"stdout","text":"Generated embeddings with shape: (1, 768)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2702753471bb495f88282acfec5405c2"}},"metadata":{}},{"name":"stdout","text":"There are several types of screws available. Mini eyeglasses, mobile phones, computers, and personal electronics often have very small screws, which in turn will require very small screwdrivers. These come in flat-head, phillips, torxâ„¢, pozidriv, and more.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"query = \"how to build a toolbox\"\n\nprint(f\"User: {query}\")\nprint(\"Chatbot: \", end=\"\", flush=True)\n\nfor text_chunk in chatbot(query,1024):\n    print(text_chunk, end=\"\", flush=True)\n\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:18:46.740225Z","iopub.execute_input":"2025-10-19T10:18:46.741010Z","iopub.status.idle":"2025-10-19T10:20:15.030900Z","shell.execute_reply.started":"2025-10-19T10:18:46.740984Z","shell.execute_reply":"2025-10-19T10:20:15.030130Z"}},"outputs":[{"name":"stdout","text":"User: how to build a toolbox\nChatbot: Generating embeddings for 1 texts ... \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"027b4bbdd67f4da78b090cebc2785201"}},"metadata":{}},{"name":"stdout","text":"Generated embeddings with shape: (1, 768)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93061462c9ea43cea36d3cf7f69204c4"}},"metadata":{}},{"name":"stdout","text":"You can't build a toolbox from scratch using the information provided. However, you can certainly build a toolbox to *hold* your tools. Hereâ€™s how to create a basic, functional toolbox:\n\n**Materials Youâ€™ll Need:**\n\n*   Plywood (Â¾ inch thick is a good choice)\n*   Wood glue\n*   Screws (1 Â½ inch)\n*   Sandpaper (various grits)\n*   Wood finish (paint, stain, or varnish â€“ optional)\n\n**Tools Youâ€™ll Need:**\n\n*   Circular saw or hand saw\n*   Drill\n*   Screwdriver\n*   Measuring tape\n*   Square\n*   Clamps\n\n**Step-by-Step Instructions:**\n\n1.  **Cut the Plywood:** Cut the plywood into the following pieces:\n    *   **Top and Bottom:** Two pieces, approximately 12â€ x 18â€ (adjust to your desired size).\n    *   **Sides:** Two pieces, approximately 12â€ x 8â€ (adjust to desired size).\n    *   **Back:** One piece, approximately 12â€ x 8â€.\n    *   **Dividers (Optional):** These will create compartments within your toolbox. Cut pieces of plywood to the desired height and width for each compartment.\n\n2.  **Assemble the Box:** Apply wood glue to the edges of the sides and attach them to the bottom piece using screws. Use clamps to hold the pieces together while the glue dries. Repeat this process for the back piece.\n\n3.  **Add the Top:** Apply wood glue to the edges of the assembled box and attach the top piece, securing it with screws.\n\n4.  **Install Dividers (Optional):** Position the dividers within the box and glue and screw them into place.\n\n5.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"query = \"list some of the big diy projects i can make in weekend\"\n\nprint(f\"User: {query}\")\nprint(\"Chatbot: \", end=\"\", flush=True)\n\nfor text_chunk in chatbot(query):\n    print(text_chunk, end=\"\", flush=True)\n\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:10:37.342719Z","iopub.execute_input":"2025-10-19T10:10:37.342943Z","iopub.status.idle":"2025-10-19T10:12:29.664207Z","shell.execute_reply.started":"2025-10-19T10:10:37.342927Z","shell.execute_reply":"2025-10-19T10:12:29.663519Z"}},"outputs":[{"name":"stdout","text":"User: list some of the big diy projects i can make in weekend\nChatbot: Generating embeddings for 1 texts ... \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cdc6a9cc9dd434fabba817c2b3c414e"}},"metadata":{}},{"name":"stdout","text":"Generated embeddings with shape: (1, 768)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"037528e9595443448314df590a24bf95"}},"metadata":{}},{"name":"stdout","text":"You can tackle a wide range of projects in a weekend with the right preparation. Here are some big DIY projects you could realistically complete:\n\n*   **Crown Molding Installation:** Youâ€™ll be able to line your living room and hallway with beautiful crown molding.\n*   **Chair Rail Installation:** Combining this with crown molding creates a more elaborate look.\n*   **Painting:** A significant room or multiple smaller rooms can be painted effectively.\n*   **Replacing Doors & Windows:** You can replace standard doors and windows.\n*   **Pouring a Concrete Slab:** While it requires some effort, a small concrete slab is achievable.\n*   **Installing Gutters and Downspouts:** This is a substantial outdoor project.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"query = \"how to fix leakages in pipes\"\n\nprint(f\"User: {query}\")\nprint(\"Chatbot: \", end=\"\", flush=True)\n\nfor text_chunk in chatbot(query):\n    print(text_chunk, end=\"\", flush=True)\n\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:12:29.665523Z","iopub.execute_input":"2025-10-19T10:12:29.665813Z","iopub.status.idle":"2025-10-19T10:13:33.798075Z","shell.execute_reply.started":"2025-10-19T10:12:29.665795Z","shell.execute_reply":"2025-10-19T10:13:33.797380Z"}},"outputs":[{"name":"stdout","text":"User: how to fix leakages in pipes\nChatbot: Generating embeddings for 1 texts ... \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5f1e1b1433348819a367b919bfbfdfd"}},"metadata":{}},{"name":"stdout","text":"Generated embeddings with shape: (1, 768)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06b27a71463d433fa45bcb59f6198f66"}},"metadata":{}},{"name":"stdout","text":"To fix leakages in pipes, you can use self-fusing silicone tape. Stretch a length of the tape and wrap it around the problem area, overlapping the tape and making sure to cover the surface on both sides of the leak. The tape will fuse to itself to form a waterproof seal.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"query = \"what are the improvements i can make in my kitchen\"\n\nprint(f\"User: {query}\")\nprint(\"Chatbot: \", end=\"\", flush=True)\n\nfor text_chunk in chatbot(query,512):\n    print(text_chunk, end=\"\", flush=True)\n\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:13:33.798842Z","iopub.execute_input":"2025-10-19T10:13:33.799058Z","iopub.status.idle":"2025-10-19T10:15:21.240809Z","shell.execute_reply.started":"2025-10-19T10:13:33.799041Z","shell.execute_reply":"2025-10-19T10:15:21.239997Z"}},"outputs":[{"name":"stdout","text":"User: what are the improvements i can make in my kitchen\nChatbot: Generating embeddings for 1 texts ... \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fee24e39e0074bf48f1fd3e149a34ed9"}},"metadata":{}},{"name":"stdout","text":"Generated embeddings with shape: (1, 768)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c9d8b0162d144daa912856683db93f2"}},"metadata":{}},{"name":"stdout","text":"You can make several improvements to your kitchen, focusing on lighting, finishes, and potentially storage.\n\nHereâ€™s a breakdown of what you can do:\n\n*   **Lighting:** Consider adding under-cabinet lighting to provide focused illumination for tasks like food preparation. You could also add pendant lighting over an island or countertop area. Combining different lighting types â€“ like recessed lighting for general illumination and task lighting for specific areas â€“ will create a more balanced and functional space.\n\n*   **Cabinet Finishes:** Over time, kitchen cabinets can look worn. A fresh coat of paint can dramatically revitalize them. You can choose from a variety of finishes like wrought iron, pewter, satin nickel, or painted finishes. Consider colored glass for an updated look.\n\n*   **Storage:** If you have limited space, look for ways to optimize storage. You could convert the space under a staircase into a closet, build storage bins under a deck, or add a garden shed for lawn tools. Carpet tiles are a good option for targeted areas of the home.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"!zip -r /kaggle/working/vectordb.zip /kaggle/working/vectordb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:31:03.667474Z","iopub.execute_input":"2025-10-19T10:31:03.667990Z","iopub.status.idle":"2025-10-19T10:31:04.263489Z","shell.execute_reply.started":"2025-10-19T10:31:03.667965Z","shell.execute_reply":"2025-10-19T10:31:04.262722Z"}},"outputs":[{"name":"stdout","text":"  adding: kaggle/working/vectordb/ (stored 0%)\n  adding: kaggle/working/vectordb/collection/ (stored 0%)\n  adding: kaggle/working/vectordb/collection/KnowDIY_DB/ (stored 0%)\n  adding: kaggle/working/vectordb/collection/KnowDIY_DB/storage.sqlite","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":" (deflated 53%)\n  adding: kaggle/working/vectordb/.lock (stored 0%)\n  adding: kaggle/working/vectordb/meta.json (deflated 56%)\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"def gradio_streaming_chatbot(user_query):\n    response = \"\"\n    for chunk in chatbot(user_query.lower()):  \n        response += chunk\n        yield response  \n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"## ðŸ§° DIY Expert Assistant\")\n\n    user_input = gr.Textbox(\n        label=\"Ask your DIY question:\",\n        placeholder=\"e.g., How to fix a leaking pipe?\",\n        lines=2\n    )\n    output_box = gr.Textbox(\n        label=\"Response\",\n        placeholder=\"Answer will appear here...\",\n        lines=15\n    )\n    submit_btn = gr.Button(\"Ask\")\n\n    submit_btn.click(\n        fn=gradio_streaming_chatbot,\n        inputs=user_input,\n        outputs=output_box\n    )\n\ndemo.queue()  \ndemo.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T10:35:58.638314Z","iopub.execute_input":"2025-10-19T10:35:58.638947Z","iopub.status.idle":"2025-10-19T10:36:00.945530Z","shell.execute_reply.started":"2025-10-19T10:35:58.638911Z","shell.execute_reply":"2025-10-19T10:36:00.944772Z"}},"outputs":[{"name":"stdout","text":"* Running on local URL:  http://127.0.0.1:7863\n* Running on public URL: https://bdfa838ecc945f8d34.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://bdfa838ecc945f8d34.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stdout","text":"Generating embeddings for 1 texts ... \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34a7a63aa7a641a4a4b97ec53a76b998"}},"metadata":{}},{"name":"stdout","text":"Generated embeddings with shape: (1, 768)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2dd45f8ecf64cdbb31d9dd3c08ec1b5"}},"metadata":{}},{"name":"stdout","text":"Generating embeddings for 1 texts ... \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2147a4f2fd9744c3958e7b8cc18701b0"}},"metadata":{}},{"name":"stdout","text":"Generated embeddings with shape: (1, 768)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b9c392b7f1e4eb8ab127b36bec3c1c9"}},"metadata":{}}],"execution_count":41}]}